{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "思考过程：\n",
      "嗯，今天老师布置了一个数学题，让我比较9.9和9.11哪个大。一开始我觉得这个问题好像挺简单的，但仔细想想，可能还是有点需要注意的地方。首先，我得回忆一下小数比较的方法。老师之前教过，比较小数的时候，先看整数部分，如果整数部分相同，再依次比较小数部分的每一位数字。\n",
      "\n",
      "那这两个数的整数部分都是9，对吧？所以接下来就要比较小数部分了。9.9的小数部分是0.9，也就是十分位上是9，而9.11的小数部分是0.11，也就是十分位上是1，百分位上是1。这时候可能会有人直接觉得，9.9的十分位是9，比9.11的十分位1大，所以9.9更大。不过，我好像记得有时候需要考虑小数位数不同的情况，可能需要把位数对齐来比较。\n",
      "\n",
      "比如，把9.9写成9.90，这样小数部分就有两位了，和9.11对齐。这样的话，比较十分位的话，9.90的十分位是9，而9.11的十分位是1，9比1大，所以这时候还是9.90更大，也就是原来的9.9更大。不过，这里可能有个误区，就是有人可能会认为9.11因为有两位小数，所以数值更大，但其实小数位数多并不一定代表数值更大，关键要看每一位上的数字。\n",
      "\n",
      "再举个例子，比如0.9和0.89，0.9其实是0.90，所以比较的话，十分位9比8大，所以0.9更大。同样的道理，这里9.9等于9.90，而9.11的十分位是1，百分位是1，所以9.90比9.11大。\n",
      "\n",
      "不过，我有点担心自己是不是哪里弄错了。比如，有没有可能因为9.11的小数部分有两位，而9.9只有一位，所以需要考虑后面的位数？比如，把9.9看成9.90，这样百分位是0，而9.11的百分位是1，所以这时候是不是应该比较到百分位？不过这样的话，虽然9.11的百分位是1，而9.90的百分位是0，但十分位已经比较出结果了，所以不需要再继续比较下去，对吗？\n",
      "\n",
      "也就是说，比较小数的时候，是从左到右一位一位地比较，一旦某一位上的数字不同，就能确定大小了，不需要再比较后面的位数。比如，9.90和9.11，十分位上9比1大，所以不管百分位是什么，9.90已经更大，所以9.9确实比9.11大。\n",
      "\n",
      "不过，可能有人会误以为9.11的数值更大，因为看起来后面有更多的数字，比如11比9多，但小数部分的位数多并不一定代表数值更大。比如，0.1和0.0999，0.1虽然只有一位小数，但0.1等于0.1000，所以比0.0999大。同样地，9.9等于9.90，比9.11大。\n",
      "\n",
      "再想一下，用分数来表示的话，9.9可以写成9又9/10，也就是99/10，而9.11是9又11/100，也就是911/100。把它们通分的话，99/10等于990/100，而911/100就是911/100。这时候比较分子，990和911，显然990更大，所以990/100也就是9.9更大。\n",
      "\n",
      "这样的话，无论是通过小数位数对齐比较，还是转化为分数比较，结果都是9.9更大。不过，我还是有点不确定，是不是有其他的情况需要考虑，比如四舍五入或者其他什么，但题目里只是直接比较两个数的大小，不需要考虑近似值的问题，所以应该没问题。\n",
      "\n",
      "总结一下，比较9.9和9.11的大小时，先将小数位数对齐，9.9写成9.90，然后比较十分位，9比1大，所以9.90（即9.9）大于9.11。或者用分数的方法，转化为同分母后比较分子，同样得出9.9更大。因此，正确答案应该是9.9比9.11大。\n",
      "最终答案：\n",
      "9.9比9.11大。以下是详细的比较过程：\n",
      "\n",
      "1. **对齐小数位数**：将9.9写成9.90，使其与9.11的小数位数一致。\n",
      "2. **逐位比较**：\n",
      "   - **整数部分**：两者均为9，相等。\n",
      "   - **十分位**：9.90的十分位是9，9.11的十分位是1。由于9 > 1，此时已能确定9.90 > 9.11。\n",
      "3. **无需继续比较后续位数**，因为十分位的差异已足够得出结论。\n",
      "\n",
      "**结论**：通过对齐小数位数并逐位比较，9.9（即9.90）的十分位数字更大，因此 **9.9 > 9.11**。\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI(\n",
    "    base_url='https://dashscope.aliyuncs.com/compatible-mode/v1',\n",
    "    api_key=''\n",
    ")\n",
    "\n",
    "completion = client.chat.completions.create(\n",
    "    model=\"deepseek-r1\",  # 此处以 deepseek-r1 为例，可按需更换模型名称。\n",
    "    messages=[\n",
    "        {'role': 'user', 'content': '9.9和9.11谁大'}\n",
    "    ]\n",
    ")\n",
    "\n",
    "# 通过reasoning_content字段打印思考过程\n",
    "print(\"思考过程：\")\n",
    "print(completion.choices[0].message.reasoning_content)\n",
    "\n",
    "# 通过content字段打印最终答案\n",
    "print(\"最终答案：\")\n",
    "print(completion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatCompletion(id='chatcmpl-9e410796-ab29-9cbf-bbd0-a2fe0d781006', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='9.9比9.11大。以下是详细的比较过程：\\n\\n1. **对齐小数位数**：将9.9写成9.90，使其与9.11的小数位数一致。\\n2. **逐位比较**：\\n   - **整数部分**：两者均为9，相等。\\n   - **十分位**：9.90的十分位是9，9.11的十分位是1。由于9 > 1，此时已能确定9.90 > 9.11。\\n3. **无需继续比较后续位数**，因为十分位的差异已足够得出结论。\\n\\n**结论**：通过对齐小数位数并逐位比较，9.9（即9.90）的十分位数字更大，因此 **9.9 > 9.11**。', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None, reasoning_content='嗯，今天老师布置了一个数学题，让我比较9.9和9.11哪个大。一开始我觉得这个问题好像挺简单的，但仔细想想，可能还是有点需要注意的地方。首先，我得回忆一下小数比较的方法。老师之前教过，比较小数的时候，先看整数部分，如果整数部分相同，再依次比较小数部分的每一位数字。\\n\\n那这两个数的整数部分都是9，对吧？所以接下来就要比较小数部分了。9.9的小数部分是0.9，也就是十分位上是9，而9.11的小数部分是0.11，也就是十分位上是1，百分位上是1。这时候可能会有人直接觉得，9.9的十分位是9，比9.11的十分位1大，所以9.9更大。不过，我好像记得有时候需要考虑小数位数不同的情况，可能需要把位数对齐来比较。\\n\\n比如，把9.9写成9.90，这样小数部分就有两位了，和9.11对齐。这样的话，比较十分位的话，9.90的十分位是9，而9.11的十分位是1，9比1大，所以这时候还是9.90更大，也就是原来的9.9更大。不过，这里可能有个误区，就是有人可能会认为9.11因为有两位小数，所以数值更大，但其实小数位数多并不一定代表数值更大，关键要看每一位上的数字。\\n\\n再举个例子，比如0.9和0.89，0.9其实是0.90，所以比较的话，十分位9比8大，所以0.9更大。同样的道理，这里9.9等于9.90，而9.11的十分位是1，百分位是1，所以9.90比9.11大。\\n\\n不过，我有点担心自己是不是哪里弄错了。比如，有没有可能因为9.11的小数部分有两位，而9.9只有一位，所以需要考虑后面的位数？比如，把9.9看成9.90，这样百分位是0，而9.11的百分位是1，所以这时候是不是应该比较到百分位？不过这样的话，虽然9.11的百分位是1，而9.90的百分位是0，但十分位已经比较出结果了，所以不需要再继续比较下去，对吗？\\n\\n也就是说，比较小数的时候，是从左到右一位一位地比较，一旦某一位上的数字不同，就能确定大小了，不需要再比较后面的位数。比如，9.90和9.11，十分位上9比1大，所以不管百分位是什么，9.90已经更大，所以9.9确实比9.11大。\\n\\n不过，可能有人会误以为9.11的数值更大，因为看起来后面有更多的数字，比如11比9多，但小数部分的位数多并不一定代表数值更大。比如，0.1和0.0999，0.1虽然只有一位小数，但0.1等于0.1000，所以比0.0999大。同样地，9.9等于9.90，比9.11大。\\n\\n再想一下，用分数来表示的话，9.9可以写成9又9/10，也就是99/10，而9.11是9又11/100，也就是911/100。把它们通分的话，99/10等于990/100，而911/100就是911/100。这时候比较分子，990和911，显然990更大，所以990/100也就是9.9更大。\\n\\n这样的话，无论是通过小数位数对齐比较，还是转化为分数比较，结果都是9.9更大。不过，我还是有点不确定，是不是有其他的情况需要考虑，比如四舍五入或者其他什么，但题目里只是直接比较两个数的大小，不需要考虑近似值的问题，所以应该没问题。\\n\\n总结一下，比较9.9和9.11的大小时，先将小数位数对齐，9.9写成9.90，然后比较十分位，9比1大，所以9.90（即9.9）大于9.11。或者用分数的方法，转化为同分母后比较分子，同样得出9.9更大。因此，正确答案应该是9.9比9.11大。'))], created=1742188742, model='deepseek-r1', object='chat.completion', service_tier=None, system_fingerprint=None, usage=CompletionUsage(completion_tokens=1040, prompt_tokens=12, total_tokens=1052, completion_tokens_details=None, prompt_tokens_details=None))\n"
     ]
    }
   ],
   "source": [
    "print(completion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import gzip\n",
    "\n",
    "\n",
    "food_path = \"dataset/meta_Grocery_and_Gourmet_Food.json.gz\"\n",
    "kitchen_path = 'dataset/meta_Home_and_Kitchen.json.gz'\n",
    "\n",
    "movie_path = 'dataset/meta_Movies_and_TV.json.gz'\n",
    "book_path = 'dataset/meta_Books.json.gz'\n",
    "\n",
    "sport_path = 'dataset/meta_Sports_and_Outdoors.json.gz'\n",
    "cloth_path = 'dataset/meta_Clothing_Shoes_and_Jewelry.json.gz'\n",
    "\n",
    "paths = [food_path, kitchen_path, movie_path, book_path, sport_path, cloth_path]\n",
    "domains = ['Food', 'Kitchen', 'Movie', 'Book', 'Sport', 'Clothing']\n",
    "\n",
    "\n",
    "def get_meta_data(file_path):\n",
    "    with gzip.open(file_path, 'rt') as file:\n",
    "        json_data = file.read().splitlines()\n",
    "        for i in range(len(json_data)):\n",
    "            json_data[i] = eval(json_data[i])\n",
    "    return pd.DataFrame.from_dict(json_data)\n",
    "\n",
    "def get_item_list(file_path):\n",
    "    # 逐行读取文件\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        lines = file.readlines()\n",
    "\n",
    "    # 处理每一行\n",
    "    data = []\n",
    "    for line in lines:\n",
    "        row = line.strip().split('\\t')  # 按制表符分割\n",
    "        data.append(row)\n",
    "    # 转换为DataFrame\n",
    "    column = ['id', 'asin', 'index']\n",
    "    df = pd.DataFrame(data, columns=column)\n",
    "    df.set_index('index', inplace=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_messing_value(df_item_list, df_meta_data):\n",
    "    df_item_list['isin_meta_data'] = df_item_list['asin'].isin(df_meta_data['asin'])\n",
    "    count = df_item_list['isin_meta_data'].value_counts()\n",
    "    return count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "df_x = pd.read_csv(f'dataset/embedded_Food.csv', index_col='index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 29207/29207 [00:45<00:00, 644.84it/s]\n"
     ]
    }
   ],
   "source": [
    "tqdm.pandas()\n",
    "df_x['embedding'] = df_x.embedding.progress_apply(lambda x:np.array(eval(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.05657523, -0.00854861, -0.00446129, ..., -0.04391772,\n",
       "       -0.05465743,  0.01079724])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_x['embedding'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_embeddings(value):\n",
    "    return np.array(eval(value))\n",
    "\n",
    "converters = {'embedding': convert_embeddings}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_x = pd.read_csv(f'dataset/embedded_Food.csv', index_col='index', converters=converters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., ..., 0., 0., 0.])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.zeros(1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = np.vstack((result, np.zeros(1024), np.zeros(1024)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(58417, 1024)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "JSONDecodeError",
     "evalue": "Expecting property name enclosed in double quotes: line 1 column 2 (char 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mJSONDecodeError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 18\u001b[0m\n\u001b[0;32m     15\u001b[0m     i \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m     16\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m pd\u001b[38;5;241m.\u001b[39mDataFrame\u001b[38;5;241m.\u001b[39mfrom_dict(df, orient\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mindex\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m---> 18\u001b[0m df \u001b[38;5;241m=\u001b[39m getDF(sport_path)\n",
      "Cell \u001b[1;32mIn[3], line 13\u001b[0m, in \u001b[0;36mgetDF\u001b[1;34m(path)\u001b[0m\n\u001b[0;32m     11\u001b[0m i \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m     12\u001b[0m df \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m---> 13\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m d \u001b[38;5;129;01min\u001b[39;00m parse(path):\n\u001b[0;32m     14\u001b[0m   df[i] \u001b[38;5;241m=\u001b[39m d\n\u001b[0;32m     15\u001b[0m   i \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "Cell \u001b[1;32mIn[3], line 8\u001b[0m, in \u001b[0;36mparse\u001b[1;34m(path)\u001b[0m\n\u001b[0;32m      6\u001b[0m g \u001b[38;5;241m=\u001b[39m gzip\u001b[38;5;241m.\u001b[39mopen(path, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m l \u001b[38;5;129;01min\u001b[39;00m g:\n\u001b[1;32m----> 8\u001b[0m   \u001b[38;5;28;01myield\u001b[39;00m json\u001b[38;5;241m.\u001b[39mloads(l)\n",
      "File \u001b[1;32md:\\anaconda3\\envs\\ml\\Lib\\json\\__init__.py:346\u001b[0m, in \u001b[0;36mloads\u001b[1;34m(s, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[0m\n\u001b[0;32m    341\u001b[0m     s \u001b[38;5;241m=\u001b[39m s\u001b[38;5;241m.\u001b[39mdecode(detect_encoding(s), \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msurrogatepass\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    343\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m object_hook \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[0;32m    344\u001b[0m         parse_int \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m parse_float \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[0;32m    345\u001b[0m         parse_constant \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m object_pairs_hook \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m kw):\n\u001b[1;32m--> 346\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _default_decoder\u001b[38;5;241m.\u001b[39mdecode(s)\n\u001b[0;32m    347\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    348\u001b[0m     \u001b[38;5;28mcls\u001b[39m \u001b[38;5;241m=\u001b[39m JSONDecoder\n",
      "File \u001b[1;32md:\\anaconda3\\envs\\ml\\Lib\\json\\decoder.py:337\u001b[0m, in \u001b[0;36mJSONDecoder.decode\u001b[1;34m(self, s, _w)\u001b[0m\n\u001b[0;32m    332\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecode\u001b[39m(\u001b[38;5;28mself\u001b[39m, s, _w\u001b[38;5;241m=\u001b[39mWHITESPACE\u001b[38;5;241m.\u001b[39mmatch):\n\u001b[0;32m    333\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Return the Python representation of ``s`` (a ``str`` instance\u001b[39;00m\n\u001b[0;32m    334\u001b[0m \u001b[38;5;124;03m    containing a JSON document).\u001b[39;00m\n\u001b[0;32m    335\u001b[0m \n\u001b[0;32m    336\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 337\u001b[0m     obj, end \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mraw_decode(s, idx\u001b[38;5;241m=\u001b[39m_w(s, \u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m.\u001b[39mend())\n\u001b[0;32m    338\u001b[0m     end \u001b[38;5;241m=\u001b[39m _w(s, end)\u001b[38;5;241m.\u001b[39mend()\n\u001b[0;32m    339\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m end \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(s):\n",
      "File \u001b[1;32md:\\anaconda3\\envs\\ml\\Lib\\json\\decoder.py:353\u001b[0m, in \u001b[0;36mJSONDecoder.raw_decode\u001b[1;34m(self, s, idx)\u001b[0m\n\u001b[0;32m    344\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Decode a JSON document from ``s`` (a ``str`` beginning with\u001b[39;00m\n\u001b[0;32m    345\u001b[0m \u001b[38;5;124;03ma JSON document) and return a 2-tuple of the Python\u001b[39;00m\n\u001b[0;32m    346\u001b[0m \u001b[38;5;124;03mrepresentation and the index in ``s`` where the document ended.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    350\u001b[0m \n\u001b[0;32m    351\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    352\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 353\u001b[0m     obj, end \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscan_once(s, idx)\n\u001b[0;32m    354\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m    355\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m JSONDecodeError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpecting value\u001b[39m\u001b[38;5;124m\"\u001b[39m, s, err\u001b[38;5;241m.\u001b[39mvalue) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[1;31mJSONDecodeError\u001b[0m: Expecting property name enclosed in double quotes: line 1 column 2 (char 1)"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import gzip\n",
    "import json\n",
    "\n",
    "def parse(path):\n",
    "  g = gzip.open(path, 'rb')\n",
    "  for l in g:\n",
    "    yield json.loads(l)\n",
    "\n",
    "def getDF(path):\n",
    "  i = 0\n",
    "  df = {}\n",
    "  for d in parse(path):\n",
    "    df[i] = d\n",
    "    i += 1\n",
    "  return pd.DataFrame.from_dict(df, orient='index')\n",
    "\n",
    "df = getDF(sport_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "UnicodeDecodeError",
     "evalue": "'utf-8' codec can't decode byte 0x8b in position 1: invalid start byte",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnicodeDecodeError\u001b[0m                        Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m file_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdataset-single_domain\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdomains[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mlist.txt\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m      2\u001b[0m df_item_list \u001b[38;5;241m=\u001b[39m get_item_list(file_path)\n\u001b[1;32m----> 3\u001b[0m df_meta_data \u001b[38;5;241m=\u001b[39m get_meta_data(paths[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m])\n\u001b[0;32m      4\u001b[0m count \u001b[38;5;241m=\u001b[39m check_messing_value(df_item_list, df_meta_data)\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdomains[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m:\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "Cell \u001b[1;32mIn[10], line 20\u001b[0m, in \u001b[0;36mget_meta_data\u001b[1;34m(file_path)\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_meta_data\u001b[39m(file_path):\n\u001b[0;32m     19\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m gzip\u001b[38;5;241m.\u001b[39mopen(file_path, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrt\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m file:\n\u001b[1;32m---> 20\u001b[0m         json_data \u001b[38;5;241m=\u001b[39m file\u001b[38;5;241m.\u001b[39mread()\u001b[38;5;241m.\u001b[39msplitlines()\n\u001b[0;32m     21\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(json_data)):\n\u001b[0;32m     22\u001b[0m             json_data[i] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28meval\u001b[39m(json_data[i])\n",
      "File \u001b[1;32m<frozen codecs>:322\u001b[0m, in \u001b[0;36mdecode\u001b[1;34m(self, input, final)\u001b[0m\n",
      "\u001b[1;31mUnicodeDecodeError\u001b[0m: 'utf-8' codec can't decode byte 0x8b in position 1: invalid start byte"
     ]
    }
   ],
   "source": [
    "file_path = f'dataset-single_domain\\{domains[-2]}\\list.txt'\n",
    "df_item_list = get_item_list(file_path)\n",
    "df_meta_data = get_meta_data(paths[-2])\n",
    "count = check_messing_value(df_item_list, df_meta_data)\n",
    "print(f'{domains[-2]}:')\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.543559338088345"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "k=10\n",
    "res = sum([1.0/math.log(i+2, 2) for i in range(k)])\n",
    "res"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
