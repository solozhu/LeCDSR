# LeCDSR: Large Language Model Enhanced Cross-Domain Sequential Recommendation

The implementation of the paper:

Shuliang Wang, Jiabao Zhu, Kaibo Wang, Sijie Ruan, "**LeCDSR: Large Language Model Enhanced Cross-Domain Sequential Recommendation**", in the Information Fusion.

paper link:  [https://doi.org/10.1016/j.inffus.2025.103762](https://doi.org/10.1016/j.inffus.2025.103762)

Contact: jiabao@bit.edu.cn

Feel free to send me an email if you have any questions.

Please cite our paper if you find our code useful. Thanks!

Bibtex

```
@article{WANG2025103762,
title = {LeCDSR: Large Language Model Enhanced Cross-Domain Sequential Recommendation},
journal = {Information Fusion},
pages = {103762},
year = {2025},
issn = {1566-2535},
doi = {https://doi.org/10.1016/j.inffus.2025.103762},
url = {https://www.sciencedirect.com/science/article/pii/S1566253525008243},
author = {Shuliang Wang and Jiabao Zhu and Kaibo Wang and Sijie Ruan},
}
```

## Environments

- python 3.11
- PyTorch
- numpy

## Dataset
Due to size limitations, the original files (available for download at [Amazon review data](https://cseweb.ucsd.edu/~jmcauley/datasets/amazon_v2/)) and all generated textual data are not provided; please download them at [Google Drive](https://drive.google.com/drive/folders/1YDM6RFZIGi9_LMLm7gtV3VB2ytrolgiN?usp=sharing) or [Baidu Netdisk](https://pan.baidu.com/s/18FZE8-XwXdCP4mjnGMtDQg?pwd=y1s1)The dataset is located in the `dataset/` folder and contains three real-world datasets from Amazon Reviews. It includes user-profile embeddings and item-description embeddings generated by large language models.

### Embedding Generation
The code for generating embeddings and constructing part of the datasets is located in `LLM_emb_generator/`. It contains the large-language-model APIs and prompts used for embedding generation. 

## Example to run the code
Train and evaluate the model (you are strongly recommended to run the program on a machine with a GPU):

python main.py

`demo.ipynb` is a demo to evaluate what exactly the model outputs. After training a model, you can load the parameters and trace back to the text item description.



